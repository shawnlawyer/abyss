HELP = {
    'datasets_dir': 'Directory for the training datasets.',
    'models_dir': 'Directory for the model file.',
    'model_filename': 'Filename for the model file.',
    'train_data': 'Name of the train data file.',
    'test_data': 'Name of the test data file.',
    'max_length': 'Maximum sequence length.',
    'batch_size': 'Batch size.',
    'sample_size': 'Sample size.',
    'randomize_sample': 'Randomize Sample.',
    'epochs': 'Number of epochs.',
    'learning_rate': 'Learning rate for the optimizer.',
    'learning_rate_decay': 'Learning rate decay factor.',
    'embedding_size': 'Embedding dimension for the input layer.',
    'recurrent_units': 'Number of units for the recurrent layer(s).',
    'vocab_size': 'Size of the vocabulary.',
    'early_stopping_patience': 'Patience for early stopping.',
    'gradient_clip': 'Gradient clipping threshold.',
    'logs_dir': 'Directory for TensorBoard logs.',
    'recurrent_layers': 'Number of recurrent layers.',
    'recurrent_type': 'Type of the recurrent layer (LSTM or GRU).',
    'dropout': 'Dropout rate for the recurrent layers.',
    'recurrent_dropout': 'Recurrent dropout rate for the recurrent layers.',
    'config': 'Path to the configuration JSON file.',
    'save_config': 'Path to save the current configuration JSON file.',
    'rebuild_model': 'Build a new model instead of loading the last checkpoint.',
    'chat': 'Activate chat mode.',
    'summary': 'Activate summary mode.',
    'train': 'Activate training mode.',
    'num_responses': 'Number of responses to generate for each input.',
    'no_gpu': 'Disable GPU usage.',
    'interactive': 'Activate interactive mode.',
    'cli': 'Activate cli mode.',
    'transfer_weights': 'Path to the pre-trained model to transfer weights from.',
    'model_actions_menu': ''
}
CONFIG_FORM_LABELS = {
    "datasets": "Enter the datasets for training (default: {}): ",
    "model_filename": "Enter the filename for the model file (default: {}): ",
    "max_length": "Enter the maximum sequence length (default: {}): ",
    "batch_size": "Enter the batch size (default: {}): ",
    "sample_size": "Enter the training sample size (default: {}): ",
    "randomize_sample": "Randomize sample (default: {}): ",
    "epochs": "Enter the number of epochs (default: {}): ",
    "learning_rate": "Enter the learning rate for the optimizer (default: {}): ",
    "learning_rate_decay": "Enter the learning rate decay factor (default: {}): ",
    "embedding_size": "Enter the embedding dimension for the input layer (default: {}): ",
    "recurrent_units": "Enter the number of units for the recurrent layer(s) (default: {}): ",
    "vocab_size": "Enter the size of the vocabulary (default: {}): ",
    "early_stopping_patience": "Enter the patience for early stopping (default: {}): ",
    "gradient_clip": "Enter the gradient clipping threshold (default: {}): ",
    "recurrent_layers": "Enter the number of recurrent layers (default: {}): ",
    "recurrent_type": "Enter the type of the recurrent layer (LSTM or GRU) (default: {}): ",
    "dropout": "Enter the dropout rate for the recurrent layers (default: {}): ",
    "recurrent_dropout": "Enter the recurrent dropout rate for the recurrent layers (default: {}): ",
    "checkpoint_save_weights_only": "Enter whether the checkpoint should only save weights or the full model (default: {}): ",
    "checkpoint_save_freq": "Enter how often to save checkpoints, 'epoch' or integer (default: {}): ",
    "checkpoint_verbose": "Enter the verbosity mode for checkpoint saving, 0 or 1 (default: {}): ",
    "early_stopping_monitor": "Enter the quantity to be monitored for early stopping (default: {}): ",
    "early_stopping_restore_best_weights": "Enter whether the model weights should be restored to the state of the best observed value (default: {}): ",
    "tensorboard_write_graph": "Enter whether the graph should be visualized in Tensorboard (default: {}): ",
    "tensorboard_update_freq": "Enter the frequency (in batches or epochs) at which to write logs (default: {}): ",
    "reduce_lr_monitor": "Enter the quantity to be monitored for learning rate reduction (default: {}): ",
    "reduce_lr_factor": "Enter the factor by which to reduce learning rate (default: {}): ",
    "reduce_lr_patience": "Enter the number of epochs to wait before reducing learning rate when monitored quantity has stopped improving (default: {}): ",
    "reduce_lr_min_lr": "Enter the lower bound on the learning rate (default: {}): ",
    "reduce_lr_verbose": "Enter whether update messages should be printed when the learning rate is reduced (default: {}): ",

}